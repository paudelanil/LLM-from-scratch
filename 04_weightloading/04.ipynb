{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLXqUUicTLXT",
        "outputId": "aa1c9a23-ada6-4d77-847f-218999eb451c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.26.4\n",
            "tiktoken version: 0.7.0\n",
            "torch version: 2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEiVDmNTLXe"
      },
      "source": [
        "Previously, we only trained a small GPT-2 model using a very small short-story book for educational purposes\n",
        "Fortunately, we don't have to spend tens to hundreds of thousands of dollars to pretrain the model on a large pretraining corpus but can load pretrained weights (we start with the GPT-2 weights provided by OpenAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GlW5-SvTLXh",
        "outputId": "f2236dc4-9719-4fdb-fff9-63da3799f798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.0\n",
            "tqdm version: 4.66.5\n"
          ]
        }
      ],
      "source": [
        "# ! pip install tensorflow tqdm\n",
        "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
        "print(\"tqdm version:\", version(\"tqdm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8q0GbQ35TLXj"
      },
      "outputs": [],
      "source": [
        "# Relative import from the gpt_download.py contained in this folder\n",
        "from gpt_download import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XkRCV22NVhLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBh79UcmTLXj",
        "outputId": "e5753be8-5f64-44dc-8e0d-2ddeac512970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())\n",
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJmDK7nFTvgP",
        "outputId": "7b2eed7a-1637-4685-d9d6-c25541354de0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "\n",
        "\n",
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})"
      ],
      "metadata": {
        "id": "MaInqTedUCHS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supplementary import GPTModel\n",
        "\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "GJsyrn11UHKV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "MfM90cjIUIoE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "load_weights_into_gpt(gpt, params)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "xJJlyC63UkdK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from supplementary import (\n",
        "    generate_text_simple,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743ITz5YVIMu",
        "outputId": "d07f7dc6-e431-47b2-b9c0-e5fe11309d5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you forward.\n",
            "\n",
            "The first step is to understand\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BASIC litgpt USES**\n",
        "\n",
        "` ligpt [action] [model]`\n",
        "\n",
        "litgpt  download  meta-llama/Meta-Llama-3-8B-Instruct\n",
        "\n",
        "litgpt  chat      meta-llama/Meta-Llama-3-8B-Instruct\n",
        "\n",
        "litgpt  evaluate  meta-llama/Meta-Llama-3-8B-Instruct\n",
        "\n",
        "litgpt  finetune  meta-llama/Meta-Llama-3-8B-Instruct\n",
        "\n",
        "litgpt  pretrain  meta-llama/Meta-Llama-3-8B-Instruct\n",
        "\n",
        "litgpt  serve     meta-llama/Meta-Llama-3-8B-Instruct"
      ],
      "metadata": {
        "id": "8QbHdL1SWBxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# or we can use litgpt library for better downloads\n",
        "\n",
        "! pip install litgpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtKwffe3VP28",
        "outputId": "9c8847e8-ff64-4821-feea-651252e6ff2f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litgpt\n",
            "  Downloading litgpt-0.4.11-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt) (2.4.0+cu121)\n",
            "Collecting lightning==2.4.0.dev20240728 (from litgpt)\n",
            "  Downloading lightning-2.4.0.dev20240728-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonargparse>=4.27.6 (from jsonargparse[signatures]>=4.27.6->litgpt)\n",
            "  Downloading jsonargparse-4.32.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.5 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.4.4)\n",
            "Requirement already satisfied: tokenizers>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from litgpt) (4.66.5)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (2024.6.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (24.1)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.5->litgpt) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.5->litgpt) (2.32.3)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]>=4.27.6->litgpt) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.27.6->litgpt)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (3.1.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (3.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.4.0.dev20240728->litgpt) (71.0.4)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning==2.4.0.dev20240728->litgpt) (1.26.4)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.27.6->litgpt) (6.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->litgpt) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (4.0.3)\n",
            "Downloading litgpt-0.4.11-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0.dev20240728-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.7/808.7 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.32.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typeshed-client, lightning-utilities, jsonargparse, torchmetrics, pytorch-lightning, lightning, litgpt\n",
            "Successfully installed jsonargparse-4.32.1 lightning-2.4.0.dev20240728 lightning-utilities-0.11.7 litgpt-0.4.11 pytorch-lightning-2.4.0 torchmetrics-1.4.1 typeshed-client-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! litgpt download list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmO72P01WQDG",
        "outputId": "3f629cc6-2c0f-481b-ad7a-d3b5f5e26198"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please specify --repo_id <repo_id>. Available values:\n",
            "codellama/CodeLlama-13b-hf\n",
            "codellama/CodeLlama-13b-Instruct-hf\n",
            "codellama/CodeLlama-13b-Python-hf\n",
            "codellama/CodeLlama-34b-hf\n",
            "codellama/CodeLlama-34b-Instruct-hf\n",
            "codellama/CodeLlama-34b-Python-hf\n",
            "codellama/CodeLlama-70b-hf\n",
            "codellama/CodeLlama-70b-Instruct-hf\n",
            "codellama/CodeLlama-70b-Python-hf\n",
            "codellama/CodeLlama-7b-hf\n",
            "codellama/CodeLlama-7b-Instruct-hf\n",
            "codellama/CodeLlama-7b-Python-hf\n",
            "databricks/dolly-v2-12b\n",
            "databricks/dolly-v2-3b\n",
            "databricks/dolly-v2-7b\n",
            "EleutherAI/pythia-1.4b\n",
            "EleutherAI/pythia-1.4b-deduped\n",
            "EleutherAI/pythia-12b\n",
            "EleutherAI/pythia-12b-deduped\n",
            "EleutherAI/pythia-14m\n",
            "EleutherAI/pythia-160m\n",
            "EleutherAI/pythia-160m-deduped\n",
            "EleutherAI/pythia-1b\n",
            "EleutherAI/pythia-1b-deduped\n",
            "EleutherAI/pythia-2.8b\n",
            "EleutherAI/pythia-2.8b-deduped\n",
            "EleutherAI/pythia-31m\n",
            "EleutherAI/pythia-410m\n",
            "EleutherAI/pythia-410m-deduped\n",
            "EleutherAI/pythia-6.9b\n",
            "EleutherAI/pythia-6.9b-deduped\n",
            "EleutherAI/pythia-70m\n",
            "EleutherAI/pythia-70m-deduped\n",
            "garage-bAInd/Camel-Platypus2-13B\n",
            "garage-bAInd/Camel-Platypus2-70B\n",
            "garage-bAInd/Platypus-30B\n",
            "garage-bAInd/Platypus2-13B\n",
            "garage-bAInd/Platypus2-70B\n",
            "garage-bAInd/Platypus2-70B-instruct\n",
            "garage-bAInd/Platypus2-7B\n",
            "garage-bAInd/Stable-Platypus2-13B\n",
            "google/codegemma-7b-it\n",
            "google/gemma-2-27b\n",
            "google/gemma-2-27b-it\n",
            "google/gemma-2-2b\n",
            "google/gemma-2-2b-it\n",
            "google/gemma-2-9b\n",
            "google/gemma-2-9b-it\n",
            "google/gemma-2b\n",
            "google/gemma-2b-it\n",
            "google/gemma-7b\n",
            "google/gemma-7b-it\n",
            "h2oai/h2o-danube2-1.8b-chat\n",
            "keeeeenw/MicroLlama\n",
            "lmsys/longchat-13b-16k\n",
            "lmsys/longchat-7b-16k\n",
            "lmsys/vicuna-13b-v1.3\n",
            "lmsys/vicuna-13b-v1.5\n",
            "lmsys/vicuna-13b-v1.5-16k\n",
            "lmsys/vicuna-33b-v1.3\n",
            "lmsys/vicuna-7b-v1.3\n",
            "lmsys/vicuna-7b-v1.5\n",
            "lmsys/vicuna-7b-v1.5-16k\n",
            "meta-llama/Llama-2-13b-chat-hf\n",
            "meta-llama/Llama-2-13b-hf\n",
            "meta-llama/Llama-2-70b-chat-hf\n",
            "meta-llama/Llama-2-70b-hf\n",
            "meta-llama/Llama-2-7b-chat-hf\n",
            "meta-llama/Llama-2-7b-hf\n",
            "meta-llama/Meta-Llama-3-70B\n",
            "meta-llama/Meta-Llama-3-70B-Instruct\n",
            "meta-llama/Meta-Llama-3-8B\n",
            "meta-llama/Meta-Llama-3-8B-Instruct\n",
            "meta-llama/Meta-Llama-3.1-405B\n",
            "meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "meta-llama/Meta-Llama-3.1-70B\n",
            "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "meta-llama/Meta-Llama-3.1-8B\n",
            "meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "microsoft/phi-1_5\n",
            "microsoft/phi-2\n",
            "microsoft/Phi-3-mini-4k-instruct\n",
            "microsoft/Phi-3.5-mini-instruct\n",
            "mistralai/mathstral-7B-v0.1\n",
            "mistralai/Mistral-7B-Instruct-v0.1\n",
            "mistralai/Mistral-7B-Instruct-v0.2\n",
            "mistralai/Mistral-7B-Instruct-v0.3\n",
            "mistralai/Mistral-7B-v0.1\n",
            "mistralai/Mistral-7B-v0.3\n",
            "mistralai/Mistral-Large-Instruct-2407\n",
            "mistralai/Mixtral-8x7B-Instruct-v0.1\n",
            "mistralai/Mixtral-8x7B-v0.1\n",
            "NousResearch/Nous-Hermes-13b\n",
            "NousResearch/Nous-Hermes-llama-2-7b\n",
            "NousResearch/Nous-Hermes-Llama2-13b\n",
            "openlm-research/open_llama_13b\n",
            "openlm-research/open_llama_3b\n",
            "openlm-research/open_llama_7b\n",
            "stabilityai/FreeWilly2\n",
            "stabilityai/stable-code-3b\n",
            "stabilityai/stablecode-completion-alpha-3b\n",
            "stabilityai/stablecode-completion-alpha-3b-4k\n",
            "stabilityai/stablecode-instruct-alpha-3b\n",
            "stabilityai/stablelm-3b-4e1t\n",
            "stabilityai/stablelm-base-alpha-3b\n",
            "stabilityai/stablelm-base-alpha-7b\n",
            "stabilityai/stablelm-tuned-alpha-3b\n",
            "stabilityai/stablelm-tuned-alpha-7b\n",
            "stabilityai/stablelm-zephyr-3b\n",
            "tiiuae/falcon-180B\n",
            "tiiuae/falcon-180B-chat\n",
            "tiiuae/falcon-40b\n",
            "tiiuae/falcon-40b-instruct\n",
            "tiiuae/falcon-7b\n",
            "tiiuae/falcon-7b-instruct\n",
            "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
            "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
            "togethercomputer/LLaMA-2-7B-32K\n",
            "togethercomputer/RedPajama-INCITE-7B-Base\n",
            "togethercomputer/RedPajama-INCITE-7B-Chat\n",
            "togethercomputer/RedPajama-INCITE-7B-Instruct\n",
            "togethercomputer/RedPajama-INCITE-Base-3B-v1\n",
            "togethercomputer/RedPajama-INCITE-Base-7B-v0.1\n",
            "togethercomputer/RedPajama-INCITE-Chat-3B-v1\n",
            "togethercomputer/RedPajama-INCITE-Chat-7B-v0.1\n",
            "togethercomputer/RedPajama-INCITE-Instruct-3B-v1\n",
            "togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1\n",
            "Trelis/Llama-2-7b-chat-hf-function-calling-v2\n",
            "unsloth/Mistral-7B-v0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt download microsoft/phi-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT6c-FQdWVhJ",
        "outputId": "c464bf10-b108-42be-f851-bf80c421d252"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching 7 files:   0% 0/7 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer.json:   0% 0.00/2.11M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 7.34k/7.34k [00:00<00:00, 36.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 735/735 [00:00<00:00, 4.74MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json:   0% 0.00/35.7k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 976kB/s]\n",
            "model.safetensors.index.json: 100% 35.7k/35.7k [00:00<00:00, 28.4MB/s]\n",
            "Fetching 7 files:  14% 1/7 [00:00<00:04,  1.43it/s]\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/5.00G [00:00<01:48, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/5.00G [00:00<01:47, 46.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/564M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 21.0M/564M [00:00<00:02, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/5.00G [00:00<01:46, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 62.9M/564M [00:00<00:01, 292MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/5.00G [00:00<01:36, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 105M/564M [00:00<00:01, 303MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 136M/564M [00:00<00:01, 305MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:01<00:00, 2.10MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/5.00G [00:01<01:38, 50.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 168M/564M [00:00<00:01, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/5.00G [00:01<01:36, 51.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 210M/564M [00:00<00:01, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 241M/564M [00:00<00:01, 293MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/5.00G [00:01<01:24, 58.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 273M/564M [00:00<00:01, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/5.00G [00:01<01:25, 57.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 304M/564M [00:01<00:00, 293MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 336M/564M [00:01<00:00, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/5.00G [00:01<01:29, 54.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 367M/564M [00:01<00:00, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 398M/564M [00:01<00:00, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/5.00G [00:02<01:32, 52.7MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 430M/564M [00:01<00:00, 247MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/5.00G [00:02<01:33, 52.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 461M/564M [00:01<00:00, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 493M/564M [00:01<00:00, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/5.00G [00:02<01:31, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/5.00G [00:02<01:31, 53.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 524M/564M [00:03<00:00, 44.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/5.00G [00:04<05:23, 15.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 556M/564M [00:04<00:00, 58.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 564M/564M [00:04<00:00, 138MB/s] \n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 178M/5.00G [00:04<02:42, 29.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/5.00G [00:04<02:21, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/5.00G [00:05<02:05, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/5.00G [00:05<01:53, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/5.00G [00:05<01:46, 44.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/5.00G [00:05<01:46, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/5.00G [00:06<01:46, 44.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/5.00G [00:06<01:44, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/5.00G [00:06<01:43, 45.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/5.00G [00:06<01:39, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/5.00G [00:06<01:37, 48.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/5.00G [00:07<01:37, 48.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/5.00G [00:07<01:36, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/5.00G [00:07<01:36, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/5.00G [00:07<01:36, 48.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/5.00G [00:07<01:37, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/5.00G [00:08<01:32, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/5.00G [00:08<01:34, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/5.00G [00:08<01:36, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/5.00G [00:08<01:34, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/5.00G [00:08<01:31, 50.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/5.00G [00:09<01:27, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/5.00G [00:09<01:23, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/5.00G [00:09<01:19, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/5.00G [00:09<01:19, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/5.00G [00:09<01:20, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/5.00G [00:10<01:26, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/5.00G [00:10<01:25, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 472M/5.00G [00:10<01:23, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/5.00G [00:10<01:24, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/5.00G [00:10<01:23, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/5.00G [00:11<01:23, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/5.00G [00:11<01:23, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 524M/5.00G [00:11<01:25, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/5.00G [00:11<01:16, 58.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/5.00G [00:11<01:23, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/5.00G [00:12<01:25, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/5.00G [00:12<01:25, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/5.00G [00:12<01:25, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/5.00G [00:12<01:22, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/5.00G [00:12<01:24, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/5.00G [00:13<01:25, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/5.00G [00:13<01:19, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/5.00G [00:13<01:22, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/5.00G [00:13<01:20, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/5.00G [00:13<01:22, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/5.00G [00:14<01:21, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/5.00G [00:14<01:19, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/5.00G [00:14<01:18, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/5.00G [00:14<01:20, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/5.00G [00:14<01:16, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/5.00G [00:14<01:19, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 724M/5.00G [00:15<01:20, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/5.00G [00:15<01:20, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/5.00G [00:15<01:18, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/5.00G [00:15<01:18, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/5.00G [00:16<01:23, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/5.00G [00:16<01:20, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/5.00G [00:16<01:25, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/5.00G [00:16<01:21, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/5.00G [00:16<01:22, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/5.00G [00:17<01:22, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/5.00G [00:17<01:22, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/5.00G [00:17<01:21, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/5.00G [00:17<01:16, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/5.00G [00:17<01:17, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 870M/5.00G [00:18<01:21, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/5.00G [00:18<01:18, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/5.00G [00:18<01:14, 54.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/5.00G [00:18<01:16, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/5.00G [00:18<01:17, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/5.00G [00:19<01:21, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/5.00G [00:19<01:15, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/5.00G [00:19<01:15, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/5.00G [00:19<01:16, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/5.00G [00:19<01:18, 51.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/5.00G [00:20<01:15, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/5.00G [00:20<01:07, 59.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/5.00G [00:20<01:11, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/5.00G [00:20<01:15, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/5.00G [00:20<01:15, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/5.00G [00:20<01:13, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/5.00G [00:21<01:15, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/5.00G [00:21<01:14, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/5.00G [00:21<01:15, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.07G/5.00G [00:21<01:08, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/5.00G [00:21<01:12, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/5.00G [00:22<01:12, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/5.00G [00:22<01:12, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/5.00G [00:22<01:13, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/5.00G [00:22<01:14, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/5.00G [00:22<01:14, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/5.00G [00:23<01:12, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/5.00G [00:23<01:14, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/5.00G [00:23<01:11, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/5.00G [00:23<01:07, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/5.00G [00:23<01:09, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/5.00G [00:24<01:10, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/5.00G [00:24<01:08, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/5.00G [00:24<01:07, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/5.00G [00:24<01:08, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/5.00G [00:24<01:13, 51.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/5.00G [00:25<01:10, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/5.00G [00:25<01:13, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/5.00G [00:25<01:14, 49.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/5.00G [00:25<01:17, 47.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/5.00G [00:25<01:13, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/5.00G [00:26<01:13, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/5.00G [00:26<01:12, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.32G/5.00G [00:26<01:11, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/5.00G [00:26<01:11, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/5.00G [00:26<01:08, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/5.00G [00:27<01:08, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/5.00G [00:27<01:11, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.37G/5.00G [00:27<01:11, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/5.00G [00:27<01:09, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/5.00G [00:27<01:08, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/5.00G [00:28<01:05, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/5.00G [00:28<01:04, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/5.00G [00:28<01:05, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/5.00G [00:28<01:10, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/5.00G [00:28<01:11, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/5.00G [00:29<01:08, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.47G/5.00G [00:29<01:07, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/5.00G [00:29<01:09, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/5.00G [00:29<01:08, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/5.00G [00:30<01:10, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/5.00G [00:30<01:11, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.52G/5.00G [00:30<01:10, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/5.00G [00:30<01:09, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/5.00G [00:30<01:06, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/5.00G [00:30<01:03, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/5.00G [00:31<01:05, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.57G/5.00G [00:31<01:04, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/5.00G [00:31<01:04, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/5.00G [00:31<00:56, 60.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/5.00G [00:31<00:54, 62.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/5.00G [00:32<00:57, 58.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/5.00G [00:32<01:00, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/5.00G [00:32<01:01, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/5.00G [00:32<01:00, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/5.00G [00:32<01:00, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/5.00G [00:33<00:59, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/5.00G [00:33<01:01, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/5.00G [00:33<01:01, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/5.00G [00:33<01:02, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/5.00G [00:33<01:02, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.72G/5.00G [00:34<01:03, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/5.00G [00:34<01:04, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/5.00G [00:34<01:04, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/5.00G [00:34<01:04, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/5.00G [00:34<01:05, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.77G/5.00G [00:35<01:02, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/5.00G [00:35<01:02, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/5.00G [00:35<01:01, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/5.00G [00:35<00:58, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/5.00G [00:35<01:01, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/5.00G [00:36<01:02, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/5.00G [00:36<00:59, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/5.00G [00:36<00:58, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/5.00G [00:36<00:59, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/5.00G [00:36<00:57, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/5.00G [00:37<00:58, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/5.00G [00:37<00:57, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/5.00G [00:37<00:56, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/5.00G [00:37<00:53, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.92G/5.00G [00:37<00:53, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/5.00G [00:38<00:57, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/5.00G [00:38<00:53, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/5.00G [00:38<00:54, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/5.00G [00:38<00:57, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.97G/5.00G [00:38<00:57, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/5.00G [00:39<00:56, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/5.00G [00:39<00:57, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/5.00G [00:39<00:55, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.01G/5.00G [00:39<00:56, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/5.00G [00:39<00:54, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/5.00G [00:39<00:53, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/5.00G [00:40<00:56, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/5.00G [00:40<00:58, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/5.00G [00:40<00:56, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/5.00G [00:40<01:00, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/5.00G [00:41<00:57, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/5.00G [00:41<00:54, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/5.00G [00:41<00:53, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/5.00G [00:41<00:53, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/5.00G [00:41<00:53, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/5.00G [00:41<00:47, 60.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/5.00G [00:42<00:46, 61.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/5.00G [00:42<00:48, 58.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.17G/5.00G [00:42<00:48, 58.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/5.00G [00:42<00:47, 58.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/5.00G [00:42<00:45, 61.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/5.00G [00:42<00:47, 59.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/5.00G [00:43<00:47, 58.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.22G/5.00G [00:43<00:48, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/5.00G [00:43<00:48, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/5.00G [00:43<00:50, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/5.00G [00:43<00:51, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.26G/5.00G [00:44<00:49, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/5.00G [00:44<00:46, 58.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/5.00G [00:44<00:46, 58.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/5.00G [00:44<00:46, 58.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/5.00G [00:44<00:49, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/5.00G [00:45<00:49, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/5.00G [00:45<00:49, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/5.00G [00:45<00:50, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/5.00G [00:45<00:49, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/5.00G [00:45<00:50, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.37G/5.00G [00:46<00:52, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/5.00G [00:46<00:52, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/5.00G [00:46<00:51, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/5.00G [00:46<00:49, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/5.00G [00:46<00:49, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.42G/5.00G [00:47<00:46, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/5.00G [00:47<00:46, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/5.00G [00:47<00:45, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/5.00G [00:47<00:46, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/5.00G [00:47<00:45, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/5.00G [00:48<00:48, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/5.00G [00:48<00:45, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/5.00G [00:48<00:44, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/5.00G [00:48<00:43, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.52G/5.00G [00:48<00:44, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/5.00G [00:48<00:43, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/5.00G [00:49<00:45, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/5.00G [00:49<00:44, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/5.00G [00:49<00:45, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.57G/5.00G [00:49<00:42, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/5.00G [00:49<00:45, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/5.00G [00:50<00:43, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/5.00G [00:50<00:45, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/5.00G [00:50<00:44, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.62G/5.00G [00:50<00:47, 50.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/5.00G [00:50<00:47, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/5.00G [00:51<00:46, 51.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/5.00G [00:51<00:44, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/5.00G [00:51<00:45, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/5.00G [00:51<00:44, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/5.00G [00:51<00:40, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/5.00G [00:52<00:39, 58.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/5.00G [00:52<00:42, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.72G/5.00G [00:52<00:41, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/5.00G [00:52<00:43, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/5.00G [00:52<00:43, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/5.00G [00:53<00:43, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/5.00G [00:53<00:42, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.77G/5.00G [00:53<00:42, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/5.00G [00:53<00:41, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/5.00G [00:53<00:41, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/5.00G [00:54<00:38, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.81G/5.00G [00:54<00:37, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.82G/5.00G [00:54<00:37, 57.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/5.00G [00:54<00:39, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/5.00G [00:54<00:38, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/5.00G [00:55<00:41, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/5.00G [00:55<00:41, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/5.00G [00:55<00:42, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/5.00G [00:55<00:39, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/5.00G [00:55<00:43, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/5.00G [00:56<00:41, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.92G/5.00G [00:56<00:40, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/5.00G [00:56<00:40, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/5.00G [00:56<00:40, 50.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/5.00G [00:56<00:39, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.96G/5.00G [00:57<00:39, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/5.00G [00:57<00:38, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/5.00G [00:57<00:39, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/5.00G [00:57<00:38, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/5.00G [00:57<00:37, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.01G/5.00G [00:58<00:36, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.02G/5.00G [00:58<00:37, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/5.00G [00:58<00:35, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/5.00G [00:58<00:36, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/5.00G [00:58<00:36, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.06G/5.00G [00:59<00:35, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/5.00G [00:59<00:36, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/5.00G [00:59<00:36, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/5.00G [00:59<00:35, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/5.00G [00:59<00:36, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/5.00G [01:00<00:36, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/5.00G [01:00<00:37, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/5.00G [01:00<00:35, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/5.00G [01:00<00:36, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/5.00G [01:00<00:39, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.17G/5.00G [01:01<00:47, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/5.00G [01:01<00:45, 40.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/5.00G [01:01<00:41, 43.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/5.00G [01:01<00:35, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/5.00G [01:02<00:33, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.22G/5.00G [01:02<00:33, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/5.00G [01:02<00:32, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/5.00G [01:02<00:33, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/5.00G [01:02<00:33, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/5.00G [01:03<00:34, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.27G/5.00G [01:03<00:32, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/5.00G [01:03<00:30, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/5.00G [01:03<00:30, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/5.00G [01:03<00:30, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/5.00G [01:04<00:31, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/5.00G [01:04<00:30, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/5.00G [01:04<00:30, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/5.00G [01:04<00:30, 54.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/5.00G [01:04<00:30, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.37G/5.00G [01:04<00:29, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/5.00G [01:05<00:29, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/5.00G [01:05<00:30, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/5.00G [01:05<00:28, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/5.00G [01:05<00:28, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.42G/5.00G [01:05<00:27, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/5.00G [01:07<01:49, 14.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/5.00G [01:08<01:03, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.46G/5.00G [01:08<00:53, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.47G/5.00G [01:08<00:45, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/5.00G [01:08<00:40, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/5.00G [01:08<00:36, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/5.00G [01:08<00:31, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/5.00G [01:09<00:30, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/5.00G [01:09<00:30, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/5.00G [01:09<00:28, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/5.00G [01:09<00:27, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/5.00G [01:09<00:25, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/5.00G [01:10<00:26, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/5.00G [01:10<00:26, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/5.00G [01:10<00:26, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/5.00G [01:10<00:24, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.61G/5.00G [01:10<00:24, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.62G/5.00G [01:11<00:24, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/5.00G [01:11<00:25, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/5.00G [01:11<00:25, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/5.00G [01:11<00:24, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/5.00G [01:11<00:25, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/5.00G [01:12<00:21, 62.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/5.00G [01:12<00:21, 61.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/5.00G [01:12<00:21, 60.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.71G/5.00G [01:12<00:23, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/5.00G [01:12<00:23, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/5.00G [01:13<00:22, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/5.00G [01:13<00:22, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/5.00G [01:13<00:22, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.76G/5.00G [01:13<00:22, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/5.00G [01:13<00:21, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/5.00G [01:14<00:21, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/5.00G [01:14<00:22, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/5.00G [01:14<00:22, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.82G/5.00G [01:14<00:23, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/5.00G [01:14<00:23, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/5.00G [01:15<00:22, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/5.00G [01:15<00:22, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.86G/5.00G [01:15<00:20, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.87G/5.00G [01:15<00:20, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/5.00G [01:15<00:20, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/5.00G [01:16<00:20, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.90G/5.00G [01:16<00:20, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.91G/5.00G [01:16<00:21, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/5.00G [01:16<00:19, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/5.00G [01:16<00:20, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/5.00G [01:17<00:20, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/5.00G [01:17<00:20, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.96G/5.00G [01:17<00:18, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/5.00G [01:17<00:18, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/5.00G [01:17<00:18, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/5.00G [01:18<00:18, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.01G/5.00G [01:18<00:17, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.02G/5.00G [01:18<00:17, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/5.00G [01:18<00:17, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/5.00G [01:18<00:17, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/5.00G [01:18<00:16, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.06G/5.00G [01:19<00:16, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.07G/5.00G [01:19<00:16, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/5.00G [01:19<00:15, 58.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/5.00G [01:19<00:15, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/5.00G [01:19<00:17, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.12G/5.00G [01:20<00:14, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/5.00G [01:20<00:14, 60.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/5.00G [01:20<00:14, 60.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/5.00G [01:20<00:13, 60.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.16G/5.00G [01:20<00:14, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/5.00G [01:21<00:15, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/5.00G [01:21<00:15, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/5.00G [01:21<00:14, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/5.00G [01:21<00:14, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.22G/5.00G [01:21<00:14, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/5.00G [01:22<00:14, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/5.00G [01:22<00:12, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/5.00G [01:22<00:12, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.26G/5.00G [01:22<00:13, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.27G/5.00G [01:22<00:13, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/5.00G [01:23<00:13, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/5.00G [01:23<00:12, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.30G/5.00G [01:23<00:12, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.31G/5.00G [01:23<00:13, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.32G/5.00G [01:23<00:12, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/5.00G [01:23<00:12, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/5.00G [01:24<00:11, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/5.00G [01:24<00:12, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.36G/5.00G [01:24<00:12, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/5.00G [01:24<00:12, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/5.00G [01:25<00:12, 49.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/5.00G [01:25<00:12, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.40G/5.00G [01:25<00:12, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.41G/5.00G [01:25<00:11, 48.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/5.00G [01:25<00:11, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/5.00G [01:26<00:11, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.45G/5.00G [01:26<00:10, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.46G/5.00G [01:26<00:10, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.47G/5.00G [01:26<00:10, 49.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/5.00G [01:26<00:10, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/5.00G [01:27<00:09, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/5.00G [01:27<00:09, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.51G/5.00G [01:27<00:09, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.52G/5.00G [01:27<00:09, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/5.00G [01:27<00:09, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/5.00G [01:28<00:08, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.55G/5.00G [01:28<00:08, 54.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/5.00G [01:28<00:08, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/5.00G [01:28<00:07, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/5.00G [01:28<00:07, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/5.00G [01:29<00:07, 53.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.60G/5.00G [01:29<00:07, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.61G/5.00G [01:29<00:07, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/5.00G [01:29<00:06, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/5.00G [01:29<00:06, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/5.00G [01:30<00:06, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/5.00G [01:30<00:06, 51.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.67G/5.00G [01:30<00:06, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/5.00G [01:30<00:05, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/5.00G [01:30<00:05, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/5.00G [01:31<00:05, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.71G/5.00G [01:31<00:05, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.72G/5.00G [01:31<00:04, 57.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/5.00G [01:31<00:04, 61.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/5.00G [01:31<00:04, 60.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/5.00G [01:31<00:04, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.76G/5.00G [01:32<00:03, 61.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/5.00G [01:32<00:03, 68.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/5.00G [01:32<00:03, 65.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/5.00G [01:32<00:03, 62.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.80G/5.00G [01:32<00:02, 64.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/5.00G [01:32<00:03, 59.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/5.00G [01:33<00:03, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/5.00G [01:33<00:03, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/5.00G [01:33<00:03, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.85G/5.00G [01:33<00:02, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.87G/5.00G [01:33<00:02, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/5.00G [01:34<00:02, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/5.00G [01:34<00:02, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/5.00G [01:34<00:01, 49.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/5.00G [01:34<00:01, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.92G/5.00G [01:34<00:01, 51.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/5.00G [01:35<00:01, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/5.00G [01:35<00:01, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.95G/5.00G [01:35<00:00, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.96G/5.00G [01:35<00:00, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.97G/5.00G [01:35<00:00, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.98G/5.00G [01:36<00:00, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 5.00G/5.00G [01:36<00:00, 51.8MB/s]\n",
            "Fetching 7 files: 100% 7/7 [01:37<00:00, 13.87s/it]\n",
            "Converting .safetensor files to PyTorch binaries (.bin)\n",
            "checkpoints/microsoft/phi-2/model-00002-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00002-of-00002.bin\n",
            "checkpoints/microsoft/phi-2/model-00001-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00001-of-00002.bin\n",
            "Converting checkpoint files to LitGPT format.\n",
            "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'debug_mode': False,\n",
            " 'dtype': None,\n",
            " 'model_name': None}\n",
            "Loading weights: model-00002-of-00002.bin: 100% 100.0/100 [00:59<00:00,  1.67it/s]\n",
            "Saving converted checkpoint to checkpoints/microsoft/phi-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litgpt import LLM\n",
        "\n",
        "llm = LLM.load(\"microsoft/phi-2\")\n",
        "\n",
        "llm.generate(\"What do Llamas eat?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "IS49Tj1gWfIr",
        "outputId": "c8f80f57-80e1-403a-c77f-7aa4e98b22d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Llamas have a diverse diet that includes grasses, leaves, and shrubs. They are herbivores and typically graze on vegetation found in mountainous regions. Llamas are able to efficiently extract nutrients from their food, making them well'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.generate(\"What do Llamas eat?\", stream=True, max_new_tokens=200)\n",
        "for e in result:\n",
        "    print(e, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7ChuzeAW7ts",
        "outputId": "7460476a-cfe5-4a61-8f7e-67b2bb7fdd04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Llamas are herbivores, they mainly feed on grass, hay, and plants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdjAmQKPXnIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}